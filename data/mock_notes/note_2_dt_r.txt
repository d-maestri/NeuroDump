entropy = -p * log2(p) – yeah info gain is difference in entropy before and after split — okay so DT picks feature that max info gain at each node. Gini impurity also similar but faster? less bias? not 100% sure. trees go deep and then prone back? no, prune. to prevent overfitting. training error low but generalization bad. CART uses binary splits – only yes/no right? sklearn.tree.DecisionTreeClassifier(max_depth=3) — yeah that’s what prof used.
note: good to visualize trees but not for high dim data. lots of axis-aligned splits, hard to interpret when too many features. oh and trees are unstable — small data change = big model change. they said bagging can help that — RandomForest.
wait then they jumped to regularization — lasso vs ridge. ridge adds λ * sum(w²), shrinks weights, but all stay ≠ 0. Lasso adds λ * sum(|w|) — forces some to zero. ohhh good for feature selection. balance bias-variance tradeoff. λ too big = underfit. low λ = overfit. prof wrote this on board: from sklearn.linear_model import Lasso model = Lasso(alpha=0.1) model.fit(X_train, y_train)
ElasticNet = mix of both? ratio param controls mix. good when multicollinearity or many small coeffs. visualize loss function — lasso diamond corners cause zeros. interesting.
btw they said don’t scale trees but do scale for lasso etc. bcz regularization depends on magnitude. std scaling or minmax okay.
might try gridsearch to tune alpha — sklearn.model_selection.GridSearchCV
decision boundary of tree is step-like, not smooth like linear models.
ok Q: why trees overfit more than lasso? more flexible model class I think?